---
title: Auto-Encoding Variational Bayes - notes
pubDate: 2025-08-22
categories: ["ML/AI"]
description: "Diederik P. Kingma, Max Welling. Auto-Encoding Variational Bayes. https://arxiv.org/abs/1312.6114, 2013."
slug: VAE
---

言わずと知れた VAE 論文だが、理論的な骨子は次の２点。
1. 真の事後分布の近似として、認識モデルを導入
2. 再パラメータ化を行い、効率的な推定器を開発

## 認識モデル $q_{\mathbf{\phi}}(\mathbf{z}|\mathbf{x})$ の導入

*変分下限* (*variational lower bound*) $\mathcal{L}(\mathbf{\theta},\mathbf{\phi};\mathbf{x}^{(i)})$ の最大化に帰着。

-- 記法と仮定 --
- データセット $\mathbf{X}=\{\mathbf{x}^{(i)}\}_{i=1}^N$、$\mathrm{i.i.d.}$ な $N$ 個の連続サンプル $\mathbf{x}^{(i)}$ の集合。
- サンプル $\mathbf{x}^{(i)}$ は次のプロセスで無作為に生成されると仮定。
  1. $\mathbf{\theta}$ によりパラメータ付けされた事前分布 $p_{\mathbf{\theta}}(\mathbf{z})$ が連続潜在変数（*code*）$\mathbf{z}^{(i)}$ を生成。
  2. その下での条件付き分布（*decoder*）$p_{\mathbf{\theta}}(\mathbf{x}|\mathbf{z})$ が $\mathbf{x}^{(i)}$ を生成。
- $p_{\mathbf{\theta}}(\mathbf{z})$ と $p_{\mathbf{\theta}}(\mathbf{x}|\mathbf{z})$ は $\mathrm{a.e.}$ で $\mathbf{\theta}$ と $\mathbf{z}$ に関して偏微分可能と仮定。
- 認識モデル（*encoder*）$q_{\mathbf{\phi}}(\mathbf{z}|\mathbf{x})$、真の事後分布 $p_{\mathbf{\theta}}(\mathbf{z}|\mathbf{x})$ の近似。
- 周辺尤度 $\mathrm{log}p_{\mathbf{\theta}}(\mathbf{x}^{(1)},\ldots,\mathbf{x}^{(N)})=\sum_{i=1}^N\mathrm{log}p_{\mathbf{\theta}}(\mathbf{x}^{(i)})$

-- $\mathrm{log}p_{\mathbf{\theta}}(\mathbf{x}^{(i)})$ の計算 --

## 再パラメータ化トリック

変分計算の秘訣として、変分下限に新たな表現（推定器）を与える。

## Variational Auto-Encoder (VAE)

$p_{\mathbf{\theta}}(\mathbf{z})=\mathcal{N}(\mathbf{z};\mathbf{0},\mathbf{I})$、$q_{\mathbf{\phi}}(\mathbf{z}|\mathbf{x}^{(i)})=\mathcal{N}(\mathbf{z};\mathbf{\mu}^{(i)},\mathbf{\sigma}^{2(i)}\mathbf{I})$ としたものを *VAE* と呼ぶ。
